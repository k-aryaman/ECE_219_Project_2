{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0dc196b9",
      "metadata": {},
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6b2049fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fix sklearn ImportError (validate_data): upgrade scikit-learn. Run this cell once, then restart kernel and run from top.\n",
        "import subprocess\n",
        "import sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"scikit-learn\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f80d1f02",
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'validate_data' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load main dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Feature extraction from raw data.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image, text\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_vectorizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictVectorizer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureHasher\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/image.py:30\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     Hidden,\n\u001b[1;32m     17\u001b[0m     Interval,\n\u001b[1;32m     18\u001b[0m     RealNotInt,\n\u001b[1;32m     19\u001b[0m     validate_params,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatchExtractor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract_patches_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconstruct_from_patches_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m ]\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_data\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# From an image to a graph\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_edges_3d\u001b[39m(n_x, n_y, n_z\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'validate_data' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load main dataset\n",
        "df = pd.read_csv(\"main.csv\")\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "833fa67e",
      "metadata": {},
      "source": [
        "## Task 1.1 - Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22880e5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q25 (25th percentile): 11 tokens\n",
            "Q75 (75th percentile): 179 tokens\n",
            "\n",
            "--- Question 1 Report ---\n",
            "Number of reviews retained: 20497 (Short: 10463, Long: 10034)\n",
            "Average token length of Short reviews: 6.39\n",
            "Average token length of Long reviews:  493.00\n"
          ]
        }
      ],
      "source": [
        "# Token length = number of tokens (whitespace-split words) per review\n",
        "def token_length(text):\n",
        "    if pd.isna(text):\n",
        "        return 0\n",
        "    return len(str(text).split())\n",
        "\n",
        "df[\"token_length\"] = df[\"review_text\"].apply(token_length)\n",
        "lengths = df[\"token_length\"]\n",
        "\n",
        "q25 = lengths.quantile(0.25)\n",
        "q75 = lengths.quantile(0.75)\n",
        "print(f\"Q25 (25th percentile): {q25:.0f} tokens\")\n",
        "print(f\"Q75 (75th percentile): {q75:.0f} tokens\")\n",
        "\n",
        "# Retain only Short (<= q25) or Long (>= q75)\n",
        "short_mask = lengths <= q25\n",
        "long_mask = lengths >= q75\n",
        "df_task1 = df[short_mask | long_mask].copy()\n",
        "df_task1[\"pseudo_label\"] = np.where(df_task1[\"token_length\"] <= q25, \"Short\", \"Long\")\n",
        "\n",
        "n_retained = len(df_task1)\n",
        "n_short = (df_task1[\"pseudo_label\"] == \"Short\").sum()\n",
        "n_long = (df_task1[\"pseudo_label\"] == \"Long\").sum()\n",
        "avg_short = df_task1.loc[df_task1[\"pseudo_label\"] == \"Short\", \"token_length\"].mean()\n",
        "avg_long = df_task1.loc[df_task1[\"pseudo_label\"] == \"Long\", \"token_length\"].mean()\n",
        "\n",
        "print(\"\\n--- Question 1 Report ---\")\n",
        "print(f\"Number of reviews retained: {n_retained} (Short: {n_short}, Long: {n_long})\")\n",
        "print(f\"Average token length of Short reviews: {avg_short:.2f}\")\n",
        "print(f\"Average token length of Long reviews:  {avg_long:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0751e2ac",
      "metadata": {},
      "source": [
        "## Task 1.2 - Question 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675ec10e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF matrix:\n",
            "  Shape: (20497, 25085) (samples × features)\n",
            "  Sparsity: 99.6763% zero entries\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF on retained reviews (Task 1): unigrams, min_df=3, English stopwords\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1), min_df=3, stop_words=\"english\")\n",
        "X_tfidf = tfidf.fit_transform(df_task1[\"review_text\"].fillna(\"\"))\n",
        "\n",
        "print(\"TF-IDF matrix:\")\n",
        "print(f\"  Shape: {X_tfidf.shape} (samples × features)\")\n",
        "print(f\"  Sparsity: {(1 - (X_tfidf.nnz / (X_tfidf.shape[0] * X_tfidf.shape[1]))):.4%} zero entries\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284410e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MiniLM matrix:\n",
            "  Shape: (20497, 384) (samples × dimensions)\n",
            "  Dense: no sparsity (all entries are non-zero floats)\n"
          ]
        }
      ],
      "source": [
        "# MiniLM embeddings on retained reviews\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "texts = df_task1[\"review_text\"].fillna(\"\").tolist()\n",
        "X_minilm = encoder.encode(texts)\n",
        "\n",
        "print(\"MiniLM matrix:\")\n",
        "print(f\"  Shape: {X_minilm.shape} (samples × dimensions)\")\n",
        "print(f\"  Dense: no sparsity (all entries are non-zero floats)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df027d2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Question 2 Report ---\n",
            "TF-IDF: 20497 × 25085 (reviews × vocabulary)\n",
            "MiniLM: 20497 × 384 (reviews × embedding dim)\n"
          ]
        }
      ],
      "source": [
        "# Question 2 Report: matrix dimensions\n",
        "print(\"--- Question 2 Report ---\")\n",
        "print(f\"TF-IDF: {X_tfidf.shape[0]} × {X_tfidf.shape[1]} (reviews × vocabulary)\")\n",
        "print(f\"MiniLM: {X_minilm.shape[0]} × {X_minilm.shape[1]} (reviews × embedding dim)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7376fbc",
      "metadata": {},
      "source": [
        "TF-IDF produces a sparse matrix because each review uses only a small subset of the vocabulary, so most entries are zero. MiniLM produces a dense matrix because every review is a fixed-length vector of 384 floats with (effectively) no zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d3525fe",
      "metadata": {},
      "source": [
        "## Task 1.3 - Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d8c3ec",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_task1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Ground truth: Short=0, Long=1\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m y_true \u001b[38;5;241m=\u001b[39m (df_task1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpseudo_label\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLong\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Precompute reduced representations (so we don't repeat slow steps)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# TF-IDF: raw (sparse), SVD(50), SVD(50)->UMAP(50)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m svd_tfidf \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_task1' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score\n",
        "\n",
        "# Install umap-learn and hdbscan in the notebook's Python if missing (fixes \"No module named 'umap'\")\n",
        "try:\n",
        "    import umap\n",
        "    import hdbscan\n",
        "except ModuleNotFoundError:\n",
        "    import subprocess, sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"umap-learn\", \"hdbscan\", \"-q\"])\n",
        "    import umap\n",
        "    import hdbscan\n",
        "\n",
        "# Ground truth: Short=0, Long=1\n",
        "y_true = (df_task1[\"pseudo_label\"] == \"Long\").astype(int).values\n",
        "\n",
        "# Precompute reduced representations (so we don't repeat slow steps)\n",
        "# TF-IDF: raw (sparse), SVD(50), SVD(50)->UMAP(50)\n",
        "svd_tfidf = TruncatedSVD(n_components=50, random_state=42)\n",
        "X_tfidf_svd = svd_tfidf.fit_transform(X_tfidf)\n",
        "X_tfidf_umap = umap.UMAP(n_components=50, random_state=42, metric=\"cosine\").fit_transform(X_tfidf_svd)\n",
        "\n",
        "# MiniLM: raw (dense), SVD(50), UMAP(50)\n",
        "X_minilm_dense = np.asarray(X_minilm, dtype=np.float64)\n",
        "svd_minilm = TruncatedSVD(n_components=50, random_state=42)\n",
        "X_minilm_svd = svd_minilm.fit_transform(X_minilm_dense)\n",
        "X_minilm_umap = umap.UMAP(n_components=50, random_state=42, metric=\"cosine\").fit_transform(X_minilm_dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e389a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"homogeneity\": homogeneity_score(y_true, y_pred),\n",
        "        \"completeness\": completeness_score(y_true, y_pred),\n",
        "        \"v_measure\": v_measure_score(y_true, y_pred),\n",
        "        \"ARI\": adjusted_rand_score(y_true, y_pred),\n",
        "        \"AMI\": adjusted_mutual_info_score(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "# Pipelines to run: (representation, DR, X_input, run_agglo, run_hdbscan)\n",
        "# TF-IDF + None: only K-Means (sparse); Agglomerative needs dense (infeasible); HDBSCAN typically needs dense\n",
        "# TF-IDF + SVD: all three\n",
        "# TF-IDF + UMAP: all three (already SVD then UMAP)\n",
        "# MiniLM + None / SVD / UMAP: all three\n",
        "pipelines = [\n",
        "    (\"TF-IDF\", \"None\", X_tfidf, False, False),           # sparse: K-Means only\n",
        "    (\"TF-IDF\", \"SVD(50)\", X_tfidf_svd, True, True),\n",
        "    (\"TF-IDF\", \"UMAP(50)\", X_tfidf_umap, True, True),\n",
        "    (\"MiniLM\", \"None\", X_minilm_dense, True, True),\n",
        "    (\"MiniLM\", \"SVD(50)\", X_minilm_svd, True, True),\n",
        "    (\"MiniLM\", \"UMAP(50)\", X_minilm_umap, True, True),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for rep, dr_name, X, do_agglo, do_hdb in pipelines:\n",
        "    # K-Means accepts sparse; Agglomerative/HDBSCAN need dense (we skip them for TF-IDF+None to avoid huge dense matrix)\n",
        "    km = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    m = compute_metrics(y_true, km.fit_predict(X))  # X can be sparse for K-Means\n",
        "    results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"K-Means\", **m})\n",
        "    if do_agglo:\n",
        "        X_dense = X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "        ac = AgglomerativeClustering(n_clusters=2)\n",
        "        m = compute_metrics(y_true, ac.fit_predict(X_dense))\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"Agglomerative\", **m})\n",
        "    else:\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"Agglomerative\", \"homogeneity\": None, \"completeness\": None, \"v_measure\": None, \"ARI\": None, \"AMI\": None, \"skip_reason\": \"Agglomerative requires dense input; TF-IDF without DR is too large to convert.\"})\n",
        "    if do_hdb:\n",
        "        X_dense = X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "        hdb_model = hdbscan.HDBSCAN(min_cluster_size=2)\n",
        "        m = compute_metrics(y_true, hdb_model.fit_predict(X_dense))\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"HDBSCAN\", **m})\n",
        "    else:\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"HDBSCAN\", \"homogeneity\": None, \"completeness\": None, \"v_measure\": None, \"ARI\": None, \"AMI\": None, \"skip_reason\": \"HDBSCAN requires dense input; TF-IDF without DR is too large to convert.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c904c0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build table (only rows with numeric metrics)\n",
        "df_results = pd.DataFrame(results)\n",
        "# Add skip_reason column if missing\n",
        "if \"skip_reason\" not in df_results.columns:\n",
        "    df_results[\"skip_reason\"] = None\n",
        "df_metrics = df_results[df_results[\"v_measure\"].notna()].copy()\n",
        "df_skipped = df_results[df_results[\"v_measure\"].isna() & df_results[\"skip_reason\"].notna()]\n",
        "\n",
        "print(\"--- Question 3 Report ---\\n\")\n",
        "print(\"Skipped pipelines (TF-IDF + None):\")\n",
        "print(df_skipped[[\"Representation\", \"DR\", \"Clustering\", \"skip_reason\"]].to_string(index=False))\n",
        "display_cols = [\"Representation\", \"DR\", \"Clustering\", \"homogeneity\", \"completeness\", \"v_measure\", \"ARI\", \"AMI\"]\n",
        "print(\"\\nClustering agreement metrics (with ground-truth length labels):\")\n",
        "print(df_metrics[display_cols].round(4).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc0db38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary table and best pipeline\n",
        "summary = df_metrics[display_cols].round(4)\n",
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dfa1390",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best-performing pipeline (by V-measure; tie-break by ARI)\n",
        "best_idx = df_metrics.sort_values([\"v_measure\", \"ARI\"], ascending=[False, False]).index[0]\n",
        "best = df_metrics.loc[best_idx]\n",
        "print(\"Best-performing pipeline:\")\n",
        "print(f\"  Representation: {best['Representation']}, DR: {best['DR']}, Clustering: {best['Clustering']}\")\n",
        "print(f\"  Homogeneity: {best['homogeneity']:.4f}  Completeness: {best['completeness']:.4f}  V-measure: {best['v_measure']:.4f}  ARI: {best['ARI']:.4f}  AMI: {best['AMI']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
