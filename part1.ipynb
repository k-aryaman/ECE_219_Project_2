{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1"
      ],
      "id": "0dc196b9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load main dataset\n",
        "df = pd.read_csv(\"main.csv\")\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "df.head(3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total reviews: 40000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>playtime</th>\n",
              "      <th>post_date</th>\n",
              "      <th>helpfulness</th>\n",
              "      <th>review_text</th>\n",
              "      <th>recommend</th>\n",
              "      <th>early_access_review</th>\n",
              "      <th>appid</th>\n",
              "      <th>game_name</th>\n",
              "      <th>release_date</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pakistan warrior</td>\n",
              "      <td>47.8</td>\n",
              "      <td>November 3, 2023</td>\n",
              "      <td>3911</td>\n",
              "      <td>ALT + F4 best feature in the game 10/10</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1938090</td>\n",
              "      <td>Call of Duty®</td>\n",
              "      <td>Oct 27, 2022</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zuvi</td>\n",
              "      <td>1969.8</td>\n",
              "      <td>November 2, 2022</td>\n",
              "      <td>3154</td>\n",
              "      <td>SPAWN DIE, SPAWN DIE, SPAWN DIE, SPAWN DIE.-Jev</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1938090</td>\n",
              "      <td>Call of Duty®</td>\n",
              "      <td>Oct 27, 2022</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SƎXSƎN</td>\n",
              "      <td>1190.7</td>\n",
              "      <td>August 5, 2023</td>\n",
              "      <td>2821</td>\n",
              "      <td>My wife said if this review gets 100 likes, I ...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1938090</td>\n",
              "      <td>Call of Duty®</td>\n",
              "      <td>Oct 27, 2022</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               user  playtime         post_date  helpfulness  \\\n",
              "0  Pakistan warrior      47.8  November 3, 2023         3911   \n",
              "1              Zuvi    1969.8  November 2, 2022         3154   \n",
              "2            SƎXSƎN    1190.7    August 5, 2023         2821   \n",
              "\n",
              "                                         review_text  recommend  \\\n",
              "0            ALT + F4 best feature in the game 10/10       True   \n",
              "1    SPAWN DIE, SPAWN DIE, SPAWN DIE, SPAWN DIE.-Jev       True   \n",
              "2  My wife said if this review gets 100 likes, I ...       True   \n",
              "\n",
              "  early_access_review    appid      game_name  release_date  genres  \n",
              "0                 NaN  1938090  Call of Duty®  Oct 27, 2022  Action  \n",
              "1                 NaN  1938090  Call of Duty®  Oct 27, 2022  Action  \n",
              "2                 NaN  1938090  Call of Duty®  Oct 27, 2022  Action  "
            ]
          }
        }
      ],
      "id": "f80d1f02"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.1 - Question 1"
      ],
      "id": "833fa67e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Token length = number of tokens (whitespace-split words) per review\n",
        "def token_length(text):\n",
        "    if pd.isna(text):\n",
        "        return 0\n",
        "    return len(str(text).split())\n",
        "\n",
        "df[\"token_length\"] = df[\"review_text\"].apply(token_length)\n",
        "lengths = df[\"token_length\"]\n",
        "\n",
        "q25 = lengths.quantile(0.25)\n",
        "q75 = lengths.quantile(0.75)\n",
        "print(f\"Q25 (25th percentile): {q25:.0f} tokens\")\n",
        "print(f\"Q75 (75th percentile): {q75:.0f} tokens\")\n",
        "\n",
        "# Retain only Short (<= q25) or Long (>= q75)\n",
        "short_mask = lengths <= q25\n",
        "long_mask = lengths >= q75\n",
        "df_task1 = df[short_mask | long_mask].copy()\n",
        "df_task1[\"pseudo_label\"] = np.where(df_task1[\"token_length\"] <= q25, \"Short\", \"Long\")\n",
        "\n",
        "n_retained = len(df_task1)\n",
        "n_short = (df_task1[\"pseudo_label\"] == \"Short\").sum()\n",
        "n_long = (df_task1[\"pseudo_label\"] == \"Long\").sum()\n",
        "avg_short = df_task1.loc[df_task1[\"pseudo_label\"] == \"Short\", \"token_length\"].mean()\n",
        "avg_long = df_task1.loc[df_task1[\"pseudo_label\"] == \"Long\", \"token_length\"].mean()\n",
        "\n",
        "print(\"\\n--- Question 1 Report ---\")\n",
        "print(f\"Number of reviews retained: {n_retained} (Short: {n_short}, Long: {n_long})\")\n",
        "print(f\"Average token length of Short reviews: {avg_short:.2f}\")\n",
        "print(f\"Average token length of Long reviews:  {avg_long:.2f}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q25 (25th percentile): 11 tokens\n",
            "Q75 (75th percentile): 179 tokens\n",
            "\n",
            "--- Question 1 Report ---\n",
            "Number of reviews retained: 20497 (Short: 10463, Long: 10034)\n",
            "Average token length of Short reviews: 6.39\n",
            "Average token length of Long reviews:  493.00\n"
          ]
        }
      ],
      "id": "22880e5e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.2 - Question 2\n"
      ],
      "id": "0751e2ac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TF-IDF on retained reviews (Task 1): unigrams, min_df=3, English stopwords\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1), min_df=3, stop_words=\"english\")\n",
        "X_tfidf = tfidf.fit_transform(df_task1[\"review_text\"].fillna(\"\"))\n",
        "\n",
        "print(\"TF-IDF matrix:\")\n",
        "print(f\"  Shape: {X_tfidf.shape} (samples × features)\")\n",
        "print(f\"  Sparsity: {(1 - (X_tfidf.nnz / (X_tfidf.shape[0] * X_tfidf.shape[1]))):.4%} zero entries\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF-IDF matrix:\n",
            "  Shape: (20497, 25085) (samples × features)\n",
            "  Sparsity: 99.6763% zero entries\n"
          ]
        }
      ],
      "id": "675ec10e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MiniLM embeddings on retained reviews\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "texts = df_task1[\"review_text\"].fillna(\"\").tolist()\n",
        "X_minilm = encoder.encode(texts)\n",
        "\n",
        "print(\"MiniLM matrix:\")\n",
        "print(f\"  Shape: {X_minilm.shape} (samples × dimensions)\")\n",
        "print(f\"  Dense: no sparsity (all entries are non-zero floats)\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MiniLM matrix:\n",
            "  Shape: (20497, 384) (samples × dimensions)\n",
            "  Dense: no sparsity (all entries are non-zero floats)\n"
          ]
        }
      ],
      "id": "284410e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Question 2 Report: matrix dimensions\n",
        "print(\"--- Question 2 Report ---\")\n",
        "print(f\"TF-IDF: {X_tfidf.shape[0]} × {X_tfidf.shape[1]} (reviews × vocabulary)\")\n",
        "print(f\"MiniLM: {X_minilm.shape[0]} × {X_minilm.shape[1]} (reviews × embedding dim)\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Question 2 Report ---\n",
            "TF-IDF: 20497 × 25085 (reviews × vocabulary)\n",
            "MiniLM: 20497 × 384 (reviews × embedding dim)\n"
          ]
        }
      ],
      "id": "df027d2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TF-IDF produces a sparse matrix because each review uses only a small subset of the vocabulary, so most entries are zero. MiniLM produces a dense matrix because every review is a fixed-length vector of 384 floats with (effectively) no zeros."
      ],
      "id": "c7376fbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.3 - Question 3"
      ],
      "id": "1d3525fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score\n",
        "\n",
        "# Install umap-learn and hdbscan in the notebook's Python if missing (fixes \"No module named 'umap'\")\n",
        "try:\n",
        "    import umap\n",
        "    import hdbscan\n",
        "except ModuleNotFoundError:\n",
        "    import subprocess, sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"umap-learn\", \"hdbscan\", \"-q\"])\n",
        "    import umap\n",
        "    import hdbscan\n",
        "\n",
        "# Ground truth: Short=0, Long=1\n",
        "y_true = (df_task1[\"pseudo_label\"] == \"Long\").astype(int).values\n",
        "\n",
        "# Precompute reduced representations (so we don't repeat slow steps)\n",
        "# TF-IDF: raw (sparse), SVD(50), SVD(50)->UMAP(50)\n",
        "svd_tfidf = TruncatedSVD(n_components=50, random_state=42)\n",
        "X_tfidf_svd = svd_tfidf.fit_transform(X_tfidf)\n",
        "X_tfidf_umap = umap.UMAP(n_components=50, random_state=42, metric=\"cosine\").fit_transform(X_tfidf_svd)\n",
        "\n",
        "# MiniLM: raw (dense), SVD(50), UMAP(50)\n",
        "X_minilm_dense = np.asarray(X_minilm, dtype=np.float64)\n",
        "svd_minilm = TruncatedSVD(n_components=50, random_state=42)\n",
        "X_minilm_svd = svd_minilm.fit_transform(X_minilm_dense)\n",
        "X_minilm_umap = umap.UMAP(n_components=50, random_state=42, metric=\"cosine\").fit_transform(X_minilm_dense)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n",
            "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        }
      ],
      "id": "e8d8c3ec"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"homogeneity\": homogeneity_score(y_true, y_pred),\n",
        "        \"completeness\": completeness_score(y_true, y_pred),\n",
        "        \"v_measure\": v_measure_score(y_true, y_pred),\n",
        "        \"ARI\": adjusted_rand_score(y_true, y_pred),\n",
        "        \"AMI\": adjusted_mutual_info_score(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "# Pipelines to run: (representation, DR, X_input, run_agglo, run_hdbscan)\n",
        "# TF-IDF + None: only K-Means (sparse); Agglomerative needs dense (infeasible); HDBSCAN typically needs dense\n",
        "# TF-IDF + SVD: all three\n",
        "# TF-IDF + UMAP: all three (already SVD then UMAP)\n",
        "# MiniLM + None / SVD / UMAP: all three\n",
        "pipelines = [\n",
        "    (\"TF-IDF\", \"None\", X_tfidf, False, False),           # sparse: K-Means only\n",
        "    (\"TF-IDF\", \"SVD(50)\", X_tfidf_svd, True, True),\n",
        "    (\"TF-IDF\", \"UMAP(50)\", X_tfidf_umap, True, True),\n",
        "    (\"MiniLM\", \"None\", X_minilm_dense, True, True),\n",
        "    (\"MiniLM\", \"SVD(50)\", X_minilm_svd, True, True),\n",
        "    (\"MiniLM\", \"UMAP(50)\", X_minilm_umap, True, True),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for rep, dr_name, X, do_agglo, do_hdb in pipelines:\n",
        "    # K-Means accepts sparse; Agglomerative/HDBSCAN need dense (we skip them for TF-IDF+None to avoid huge dense matrix)\n",
        "    km = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    m = compute_metrics(y_true, km.fit_predict(X))  # X can be sparse for K-Means\n",
        "    results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"K-Means\", **m})\n",
        "    if do_agglo:\n",
        "        X_dense = X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "        ac = AgglomerativeClustering(n_clusters=2)\n",
        "        m = compute_metrics(y_true, ac.fit_predict(X_dense))\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"Agglomerative\", **m})\n",
        "    else:\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"Agglomerative\", \"homogeneity\": None, \"completeness\": None, \"v_measure\": None, \"ARI\": None, \"AMI\": None, \"skip_reason\": \"Agglomerative requires dense input; TF-IDF without DR is too large to convert.\"})\n",
        "    if do_hdb:\n",
        "        X_dense = X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "        hdb_model = hdbscan.HDBSCAN(min_cluster_size=2)\n",
        "        m = compute_metrics(y_true, hdb_model.fit_predict(X_dense))\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"HDBSCAN\", **m})\n",
        "    else:\n",
        "        results.append({\"Representation\": rep, \"DR\": dr_name, \"Clustering\": \"HDBSCAN\", \"homogeneity\": None, \"completeness\": None, \"v_measure\": None, \"ARI\": None, \"AMI\": None, \"skip_reason\": \"HDBSCAN requires dense input; TF-IDF without DR is too large to convert.\"})"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/opt/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n",
            "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
            "the same time. Both libraries are known to be incompatible and this\n",
            "can cause random crashes or deadlocks on Linux when loaded in the\n",
            "same Python program.\n",
            "Using threadpoolctl may cause crashes or deadlocks. For more\n",
            "information and possible workarounds, please see\n",
            "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
            "\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "id": "18e389a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build table (only rows with numeric metrics)\n",
        "df_results = pd.DataFrame(results)\n",
        "# Add skip_reason column if missing\n",
        "if \"skip_reason\" not in df_results.columns:\n",
        "    df_results[\"skip_reason\"] = None\n",
        "df_metrics = df_results[df_results[\"v_measure\"].notna()].copy()\n",
        "df_skipped = df_results[df_results[\"v_measure\"].isna() & df_results[\"skip_reason\"].notna()]\n",
        "\n",
        "print(\"--- Question 3 Report ---\\n\")\n",
        "print(\"Skipped pipelines (TF-IDF + None):\")\n",
        "print(df_skipped[[\"Representation\", \"DR\", \"Clustering\", \"skip_reason\"]].to_string(index=False))\n",
        "display_cols = [\"Representation\", \"DR\", \"Clustering\", \"homogeneity\", \"completeness\", \"v_measure\", \"ARI\", \"AMI\"]\n",
        "print(\"\\nClustering agreement metrics (with ground-truth length labels):\")\n",
        "print(df_metrics[display_cols].round(4).to_string(index=False))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Question 3 Report ---\n",
            "\n",
            "Skipped pipelines (TF-IDF + None):\n",
            "Representation   DR    Clustering                                                                    skip_reason\n",
            "        TF-IDF None Agglomerative Agglomerative requires dense input; TF-IDF without DR is too large to convert.\n",
            "        TF-IDF None       HDBSCAN       HDBSCAN requires dense input; TF-IDF without DR is too large to convert.\n",
            "\n",
            "Clustering agreement metrics (with ground-truth length labels):\n",
            "Representation       DR    Clustering  homogeneity  completeness  v_measure    ARI    AMI\n",
            "        TF-IDF     None       K-Means       0.6233        0.6248     0.6240 0.7274 0.6240\n",
            "        TF-IDF  SVD(50)       K-Means       0.0301        0.1607     0.0507 0.0057 0.0507\n",
            "        TF-IDF  SVD(50) Agglomerative       0.0276        0.1575     0.0470 0.0050 0.0470\n",
            "        TF-IDF  SVD(50)       HDBSCAN       0.3488        0.0871     0.1393 0.0538 0.1205\n",
            "        TF-IDF UMAP(50)       K-Means       0.3079        0.3139     0.3109 0.3744 0.3108\n",
            "        TF-IDF UMAP(50) Agglomerative       0.2747        0.2830     0.2788 0.3296 0.2788\n",
            "        TF-IDF UMAP(50)       HDBSCAN       0.6558        0.0821     0.1459 0.0174 0.1284\n",
            "        MiniLM     None       K-Means       0.5089        0.5093     0.5091 0.6128 0.5091\n",
            "        MiniLM     None Agglomerative       0.6603        0.6604     0.6603 0.7586 0.6603\n",
            "        MiniLM     None       HDBSCAN       0.3337        0.0779     0.1264 0.0002 0.1086\n",
            "        MiniLM  SVD(50)       K-Means       0.5084        0.5087     0.5085 0.6121 0.5085\n",
            "        MiniLM  SVD(50) Agglomerative       0.6561        0.6614     0.6587 0.7451 0.6587\n",
            "        MiniLM  SVD(50)       HDBSCAN       0.3150        0.0788     0.1261 0.0002 0.1049\n",
            "        MiniLM UMAP(50)       K-Means       0.0338        0.1579     0.0556 0.0073 0.0556\n",
            "        MiniLM UMAP(50) Agglomerative       0.0338        0.1579     0.0556 0.0073 0.0556\n",
            "        MiniLM UMAP(50)       HDBSCAN       0.6374        0.0793     0.1410 0.0011 0.1261\n"
          ]
        }
      ],
      "id": "1c904c0f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary table and best pipeline\n",
        "summary = df_metrics[display_cols].round(4)\n",
        "summary"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Representation</th>\n",
              "      <th>DR</th>\n",
              "      <th>Clustering</th>\n",
              "      <th>homogeneity</th>\n",
              "      <th>completeness</th>\n",
              "      <th>v_measure</th>\n",
              "      <th>ARI</th>\n",
              "      <th>AMI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>None</td>\n",
              "      <td>K-Means</td>\n",
              "      <td>0.6233</td>\n",
              "      <td>0.6248</td>\n",
              "      <td>0.6240</td>\n",
              "      <td>0.7274</td>\n",
              "      <td>0.6240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>SVD(50)</td>\n",
              "      <td>K-Means</td>\n",
              "      <td>0.0301</td>\n",
              "      <td>0.1607</td>\n",
              "      <td>0.0507</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>SVD(50)</td>\n",
              "      <td>Agglomerative</td>\n",
              "      <td>0.0276</td>\n",
              "      <td>0.1575</td>\n",
              "      <td>0.0470</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>SVD(50)</td>\n",
              "      <td>HDBSCAN</td>\n",
              "      <td>0.3488</td>\n",
              "      <td>0.0871</td>\n",
              "      <td>0.1393</td>\n",
              "      <td>0.0538</td>\n",
              "      <td>0.1205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>UMAP(50)</td>\n",
              "      <td>K-Means</td>\n",
              "      <td>0.3079</td>\n",
              "      <td>0.3139</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.3744</td>\n",
              "      <td>0.3108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>UMAP(50)</td>\n",
              "      <td>Agglomerative</td>\n",
              "      <td>0.2747</td>\n",
              "      <td>0.2830</td>\n",
              "      <td>0.2788</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.2788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>UMAP(50)</td>\n",
              "      <td>HDBSCAN</td>\n",
              "      <td>0.6558</td>\n",
              "      <td>0.0821</td>\n",
              "      <td>0.1459</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.1284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>None</td>\n",
              "      <td>K-Means</td>\n",
              "      <td>0.5089</td>\n",
              "      <td>0.5093</td>\n",
              "      <td>0.5091</td>\n",
              "      <td>0.6128</td>\n",
              "      <td>0.5091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>None</td>\n",
              "      <td>Agglomerative</td>\n",
              "      <td>0.6603</td>\n",
              "      <td>0.6604</td>\n",
              "      <td>0.6603</td>\n",
              "      <td>0.7586</td>\n",
              "      <td>0.6603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>None</td>\n",
              "      <td>HDBSCAN</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.0779</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.1086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>SVD(50)</td>\n",
              "      <td>K-Means</td>\n",
              "      <td>0.5084</td>\n",
              "      <td>0.5087</td>\n",
              "      <td>0.5085</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>SVD(50)</td>\n",
              "      <td>Agglomerative</td>\n",
              "      <td>0.6561</td>\n",
              "      <td>0.6614</td>\n",
              "      <td>0.6587</td>\n",
              "      <td>0.7451</td>\n",
              "      <td>0.6587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>SVD(50)</td>\n",
              "      <td>HDBSCAN</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.0788</td>\n",
              "      <td>0.1261</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.1049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>UMAP(50)</td>\n",
              "      <td>K-Means</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.1579</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>UMAP(50)</td>\n",
              "      <td>Agglomerative</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.1579</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>MiniLM</td>\n",
              "      <td>UMAP(50)</td>\n",
              "      <td>HDBSCAN</td>\n",
              "      <td>0.6374</td>\n",
              "      <td>0.0793</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.0011</td>\n",
              "      <td>0.1261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Representation        DR     Clustering  homogeneity  completeness  \\\n",
              "0          TF-IDF      None        K-Means       0.6233        0.6248   \n",
              "3          TF-IDF   SVD(50)        K-Means       0.0301        0.1607   \n",
              "4          TF-IDF   SVD(50)  Agglomerative       0.0276        0.1575   \n",
              "5          TF-IDF   SVD(50)        HDBSCAN       0.3488        0.0871   \n",
              "6          TF-IDF  UMAP(50)        K-Means       0.3079        0.3139   \n",
              "7          TF-IDF  UMAP(50)  Agglomerative       0.2747        0.2830   \n",
              "8          TF-IDF  UMAP(50)        HDBSCAN       0.6558        0.0821   \n",
              "9          MiniLM      None        K-Means       0.5089        0.5093   \n",
              "10         MiniLM      None  Agglomerative       0.6603        0.6604   \n",
              "11         MiniLM      None        HDBSCAN       0.3337        0.0779   \n",
              "12         MiniLM   SVD(50)        K-Means       0.5084        0.5087   \n",
              "13         MiniLM   SVD(50)  Agglomerative       0.6561        0.6614   \n",
              "14         MiniLM   SVD(50)        HDBSCAN       0.3150        0.0788   \n",
              "15         MiniLM  UMAP(50)        K-Means       0.0338        0.1579   \n",
              "16         MiniLM  UMAP(50)  Agglomerative       0.0338        0.1579   \n",
              "17         MiniLM  UMAP(50)        HDBSCAN       0.6374        0.0793   \n",
              "\n",
              "    v_measure     ARI     AMI  \n",
              "0      0.6240  0.7274  0.6240  \n",
              "3      0.0507  0.0057  0.0507  \n",
              "4      0.0470  0.0050  0.0470  \n",
              "5      0.1393  0.0538  0.1205  \n",
              "6      0.3109  0.3744  0.3108  \n",
              "7      0.2788  0.3296  0.2788  \n",
              "8      0.1459  0.0174  0.1284  \n",
              "9      0.5091  0.6128  0.5091  \n",
              "10     0.6603  0.7586  0.6603  \n",
              "11     0.1264  0.0002  0.1086  \n",
              "12     0.5085  0.6121  0.5085  \n",
              "13     0.6587  0.7451  0.6587  \n",
              "14     0.1261  0.0002  0.1049  \n",
              "15     0.0556  0.0073  0.0556  \n",
              "16     0.0556  0.0073  0.0556  \n",
              "17     0.1410  0.0011  0.1261  "
            ]
          }
        }
      ],
      "id": "ddc0db38"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best-performing pipeline (by V-measure; tie-break by ARI)\n",
        "best_idx = df_metrics.sort_values([\"v_measure\", \"ARI\"], ascending=[False, False]).index[0]\n",
        "best = df_metrics.loc[best_idx]\n",
        "print(\"Best-performing pipeline:\")\n",
        "print(f\"  Representation: {best['Representation']}, DR: {best['DR']}, Clustering: {best['Clustering']}\")\n",
        "print(f\"  Homogeneity: {best['homogeneity']:.4f}  Completeness: {best['completeness']:.4f}  V-measure: {best['v_measure']:.4f}  ARI: {best['ARI']:.4f}  AMI: {best['AMI']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bd3cbfdb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.4 - Question 4\n",
        "\n",
        "**Why does MiniLM perform better than TF-IDF for separating Short vs Long reviews?**  \n",
        "MiniLM encodes *wording and style*: short reviews are often formulaic (\"great game\", \"10/10\") while long reviews use more varied, elaborated language. That difference in style places them in different regions of the embedding space, so clustering aligns with length even though MiniLM does not encode length directly. TF-IDF is bag-of-words and correlates with word count, but in this setup the best pipeline was MiniLM (no DR, Agglomerative), which uses the full 384 dimensions to separate brief vs elaborated text more effectively than TF-IDF for this task."
      ],
      "id": "a2babc70"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}